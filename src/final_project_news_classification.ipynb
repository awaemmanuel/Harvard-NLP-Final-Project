{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISMT S-117 |  Text Analytics Final Project \n",
    "\n",
    "#### Project Members:\n",
    "- Praneet Singh Solanki (prs184@g.harvard.com)\n",
    "- Emmanuel Awa (ema142@g.harvard.com)\n",
    "\n",
    "## Article Classification of the Microsoft MIND Dataset - Evaluation of various NLP approaches   \n",
    "\n",
    "\n",
    "### Overview\n",
    "\n",
    "We explore various NLP approaches learned in class, gained from work and general research. We apply these knowledge to Sequence Classification, specifically news article classification using the [Microsoft MIND dataset](https://blogs.msn.com/mind-at-work-news-recommendation-challenge-for-researchers/) from the on-going compettion. \n",
    "\n",
    "Here is an excerpt describing [MIND](https://blogs.msn.com/mind-at-work-news-recommendation-challenge-for-researchers/) - Recommendation engines try to discern habits, likes and other affinity traits to anticipate what you may need or want based on past actions. News consumption can fall into these patterns: We know for instance that people go to search engines to find out more about a story, be it more background or further developments. Certain types of news and feature stories lend itself to typical user behaviors: An impending hurricane, for instance, triggers preparation research (if you’re in the path), offers of help to donate supplies or blood (if you’re nearby) and historical curiosity of past hurricanes. Even celebrity stories inspire certain common impulses: An engagement announcement will launch some to seek a peek at the ring, others to check out past (failed) relationships.\n",
    "\n",
    "How might a news recommendation system offer more stories, yet not fall into the trap of filter bubbles and echo chambers? The first thing is, you need a high-quality benchmark dataset. That’s where MIND comes in: a mammoth collection of anonymized data from user behavior logs of about 1 million people. Few companies in the world attract those kinds of numbers, and Microsoft News is one of them.  \n",
    "\n",
    "The goal of this project is to experiment, evaluate and build the news/article classification pipeline that can be leveraged ina news recommendation engine.  The recommendation engine is out of scope for this project, due to the limited timeframe, but is our north star for future work that we intend to do \n",
    "\n",
    "\n",
    "### Data Source   \n",
    "\n",
    "The MIND datasets are stored in the West/East US data centers making it readily available, geographically, for anyone that is interested in participating in the competition.  \n",
    "\n",
    "\n",
    "### NLP Techniques Summary \n",
    "\n",
    "We applied our learnings from the class, experimenting and reporting the different NLP approaches. Below is a summary of what this notebook covers. Details will be expanded upon as we go along. \n",
    "\n",
    "1. Tokenization strategies  \n",
    "\n",
    "1. Vectorization using CountVectorization, TfIdfVectorization  \n",
    "\n",
    "1. Topic Modelling using NMF and LDA  \n",
    "\n",
    "1. Larger context vectorization using GloVE and using Multiple Transformer Models  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "required = {'scikit-learn', 'numpy', 'scrapbook',\n",
    "            'pandas', 'matplotlib',\n",
    "            'transformers==2.10.0'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "import tempfile\n",
    "import urllib\n",
    "import zipfile\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from spacy.lang.en import English\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Our code components\n",
    "from common.article_classification_dataset import (\n",
    "    ArticleClassificationDataProcessor,\n",
    "    ArticleClassificationDataSet,\n",
    ")\n",
    "from common.article_classification_model import ArticleClassifier\n",
    "from common.article_classification_utilities import DownloadMindDataset, Timer\n",
    "from common.plots import pca_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_md\n",
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()\n",
    "en = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook parameters\n",
    "CACHE_DIR = TemporaryDirectory().name\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "MAX_LEN = 100\n",
    "MODEL_NAMES = [\"distilbert-base-uncased\", \"roberta-base\", \"xlnet-base-cased\"]\n",
    "MODEL_RESULTS = dict()\n",
    "LABEL_COL = \"category\"\n",
    "TEXT_COL = \"text\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a sample of the data quickly  \n",
    "\n",
    "We've have provided a flag `QUICK_RUN` that is set to `True` by default. This will create a smaller subset of both the training and test datasets to enable a fast evaluation.  \n",
    "\n",
    "> **NOTE**: Running with `QUICK_RUN = True` may not guarantee the best results, especially for the transfomer models that thrive on more data during training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUICK_RUN = True\n",
    "TRAINING_FRAC = 1\n",
    "TEST_FRAC = 1\n",
    "\n",
    "if QUICK_RUN:\n",
    "    TRAINING_FRAC = 0.2\n",
    "    TEST_FRAC = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the files with pandas  \n",
    " The news.tsv file contains the detailed information of news articles involved in the behaviors.tsv file.\n",
    " It has 7 columns, which are divided by the tab symbol:\n",
    " - News ID\n",
    " - Category\n",
    " - Subcategory\n",
    " - Title\n",
    " - Abstract\n",
    " - URL\n",
    " - Title Entities (entities contained in the title of this news)\n",
    " - Abstract Entities (entities contained in the abstract of this news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Process MIND Dataset  \n",
    "\n",
    "Using `DownloadMindDataset.process_and_load_dfs()` returns the training and test dataframes.  \n",
    "\n",
    "> - Using defaults sets the data directory to `mind_dataset` and downloads small set\n",
    "> - If the data is already downloaded, the download process is skipped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bypassing download of already-downloaded file MINDsmall_train.zip\n",
      "Bypassing download of already-downloaded file MINDsmall_dev.zip\n",
      "Downloading and extraction complete!\n",
      "Train:  ['behaviors.tsv', 'relation_embedding.vec', 'https_mind201910small.blob.core.windows.net_release_MINDsmall_train.zip', 'entity_embedding.vec', 'news.tsv']\n",
      "Test:  ['behaviors.tsv', 'relation_embedding.vec', 'entity_embedding.vec', 'news.tsv', 'https_mind201910small.blob.core.windows.net_release_MINDsmall_dev.zip']\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = DownloadMindDataset.process_and_load_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>title_entities</th>\n",
       "      <th>abstract_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N55528</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAGH0ET.html</td>\n",
       "      <td>[{\"Label\": \"Prince Philip, Duke of Edinburgh\",...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N19639</td>\n",
       "      <td>health</td>\n",
       "      <td>weightloss</td>\n",
       "      <td>50 Worst Habits For Belly Fat</td>\n",
       "      <td>These seemingly harmless habits are holding yo...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAB19MK.html</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N61837</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJgNsz.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N53526</td>\n",
       "      <td>health</td>\n",
       "      <td>voices</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AACk2N6.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"National Basketball Association\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N38324</td>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
       "      <td>They seem harmless, but there's a very good re...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAAKEkt.html</td>\n",
       "      <td>[{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...</td>\n",
       "      <td>[{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   category      subcategory  \\\n",
       "0  N55528  lifestyle  lifestyleroyals   \n",
       "1  N19639     health       weightloss   \n",
       "2  N61837       news        newsworld   \n",
       "3  N53526     health           voices   \n",
       "4  N38324     health          medical   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1                      50 Worst Habits For Belly Fat   \n",
       "2  The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "3  I Was An NBA Wife. Here's How It Affected My M...   \n",
       "4  How to Get Rid of Skin Tags, According to a De...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Shop the notebooks, jackets, and more that the...   \n",
       "1  These seemingly harmless habits are holding yo...   \n",
       "2  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
       "3  I felt like I was a fraud, and being an NBA wi...   \n",
       "4  They seem harmless, but there's a very good re...   \n",
       "\n",
       "                                             url  \\\n",
       "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
       "1  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
       "2  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
       "3  https://assets.msn.com/labs/mind/AACk2N6.html   \n",
       "4  https://assets.msn.com/labs/mind/AAAKEkt.html   \n",
       "\n",
       "                                      title_entities  \\\n",
       "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
       "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...   \n",
       "\n",
       "                                   abstract_entities  \n",
       "0                                                 []  \n",
       "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
       "2  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
       "3  [{\"Label\": \"National Basketball Association\", ...  \n",
       "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>title_entities</th>\n",
       "      <th>abstract_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N55528</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAGH0ET.html</td>\n",
       "      <td>[{\"Label\": \"Prince Philip, Duke of Edinburgh\",...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N19639</td>\n",
       "      <td>health</td>\n",
       "      <td>weightloss</td>\n",
       "      <td>50 Worst Habits For Belly Fat</td>\n",
       "      <td>These seemingly harmless habits are holding yo...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAB19MK.html</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N61837</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJgNsz.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N53526</td>\n",
       "      <td>health</td>\n",
       "      <td>voices</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AACk2N6.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"National Basketball Association\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N38324</td>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
       "      <td>They seem harmless, but there's a very good re...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAAKEkt.html</td>\n",
       "      <td>[{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...</td>\n",
       "      <td>[{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   category      subcategory  \\\n",
       "0  N55528  lifestyle  lifestyleroyals   \n",
       "1  N19639     health       weightloss   \n",
       "2  N61837       news        newsworld   \n",
       "3  N53526     health           voices   \n",
       "4  N38324     health          medical   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1                      50 Worst Habits For Belly Fat   \n",
       "2  The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "3  I Was An NBA Wife. Here's How It Affected My M...   \n",
       "4  How to Get Rid of Skin Tags, According to a De...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Shop the notebooks, jackets, and more that the...   \n",
       "1  These seemingly harmless habits are holding yo...   \n",
       "2  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
       "3  I felt like I was a fraud, and being an NBA wi...   \n",
       "4  They seem harmless, but there's a very good re...   \n",
       "\n",
       "                                             url  \\\n",
       "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
       "1  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
       "2  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
       "3  https://assets.msn.com/labs/mind/AACk2N6.html   \n",
       "4  https://assets.msn.com/labs/mind/AAAKEkt.html   \n",
       "\n",
       "                                      title_entities  \\\n",
       "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
       "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...   \n",
       "\n",
       "                                   abstract_entities  \n",
       "0                                                 []  \n",
       "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
       "2  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
       "3  [{\"Label\": \"National Basketball Association\", ...  \n",
       "4  [{\"Label\": \"Skin tag\", \"Type\": \"C\", \"WikidataI...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head())\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51282, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(42416, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.shape)\n",
    "display(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this notebook, we fine-tune and evaluate a number of pretrained models on a subset of the [Microsoft MIND Dataset](https://blogs.msn.com/mind-at-work-news-recommendation-challenge-for-researchers/) dataset.\n",
    "\n",
    "We use a `ArticleClassifier` that wraps [Hugging Face's PyTorch implementation](https://github.com/huggingface/transformers) of different transformers, like [BERT](https://github.com/google-research/bert), [XLNet](https://github.com/zihangdai/xlnet), and [RoBERTa](https://github.com/pytorch/fairseq).  \n",
    "\n",
    "It also adapts some of the work done on [Microsoft NLP Recipes](https://github.com/microsoft/nlp) to implement the `ArticleClassifier` and other reusable components that make it easy to fit these transfomer models.  \n",
    "\n",
    "We leveraged Hugging Face's latest `AutoModels` architecture to help us infer the different transformer models we used for this article classification.  \n",
    "\n",
    "We fine-tuned the transformer models on Microsoft Azure GPU machines with a configuration of 1 Tesla K80 GPU with 56 GiB RAM. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset\n",
    "We start by loading a subset of the data. The following function also downloads and extracts the files, if they don't exist in the data folder.\n",
    "\n",
    "The MultiNLI dataset is mainly used for natural language inference (NLI) tasks, where the inputs are sentence pairs and the labels are entailment indicators. The sentence pairs are also classified into *genres* that allow for more coverage and better evaluation of NLI models.\n",
    "\n",
    "For our classification task, we use the first sentence only as the text input, and the corresponding genre as the label. We select the examples corresponding to one of the entailment labels (*neutral* in this case) to avoid duplicate rows, as the sentences are not unique, whereas the sentence pairs are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[[\"title\", \"abstract\", \"category\"]]\n",
    "df_test = df_test[[\"title\", \"abstract\", \"category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "abstract    2666\n",
       "category       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "abstract    2021\n",
       "category       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the data, we observed that there are rows with NaN. This is interesting, because you would expect that from a numerical data and not text. However, we need to spend some time data wrangling and cleaning.  \n",
    "\n",
    "1. First, we remove the rows with Nan\n",
    "1. To avoid scrapping the entire news article with their links, we decided to use a combination of the news title and abstract, from the MIND dataset, as the full text to train our classifiers\n",
    "1. There is a category of article called `news`. We decided to choose the top unique 6 categories removing the `news` category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title       0\n",
       "abstract    0\n",
       "category    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title       0\n",
       "abstract    0\n",
       "category    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48616, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(40395, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.shape)\n",
    "display(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the title and abstract to form long enough text to finetune our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"text\"] = df_train[\"title\"].astype(str) + df_train[\"abstract\"].astype(str)\n",
    "df_train.drop(columns=['title', 'abstract'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lifestyle</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>health</td>\n",
       "      <td>50 Worst Habits For Belly FatThese seemingly h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>health</td>\n",
       "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                               text\n",
       "0  lifestyle  The Brands Queen Elizabeth, Prince Charles, an...\n",
       "1     health  50 Worst Habits For Belly FatThese seemingly h...\n",
       "2       news  The Cost of Trump's Aid Freeze in the Trenches...\n",
       "3     health  I Was An NBA Wife. Here's How It Affected My M...\n",
       "4     health  How to Get Rid of Skin Tags, According to a De..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(48616, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head())\n",
    "display(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"text\"] = df_test[\"title\"].astype(str) + df_test[\"abstract\"].astype(str)\n",
    "df_test.drop(columns=['title', 'abstract'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lifestyle</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>health</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>health</td>\n",
       "      <td>How to Get Rid of Skin Tags, According to a De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sports</td>\n",
       "      <td>Should NFL be able to fine players for critici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                               text\n",
       "0  lifestyle  The Brands Queen Elizabeth, Prince Charles, an...\n",
       "2       news  The Cost of Trump's Aid Freeze in the Trenches...\n",
       "3     health  I Was An NBA Wife. Here's How It Affected My M...\n",
       "4     health  How to Get Rid of Skin Tags, According to a De...\n",
       "5     sports  Should NFL be able to fine players for critici..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(40395, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_test.head())\n",
    "display(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the data to only interesting article types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of the categories\n",
    "df_train.category.value_counts().plot.bar(title=\"News Categories\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose top interesting categories\n",
    "chosen_articles = [\n",
    "    \"sports\",\n",
    "    \"finance\",\n",
    "    \"foodanddrink\",\n",
    "    \"health\",\n",
    "    \"travel\",\n",
    "    \"weather\",\n",
    "    \"movies\",\n",
    "    \"music\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48616, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.shape)\n",
    "df_train = df_train[df_train.category.isin(chosen_articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40395, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_test.shape)\n",
    "df_test = df_test[df_test.category.isin(chosen_articles)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a smaller subset of data if `QUICK_RUN = True`  \n",
    "\n",
    "Depending on the parameters set above, we may or may not be sampling a smaller set of data for further downstream processing.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and reset index\n",
    "df_train = df_train.sample(frac=TRAINING_FRAC).reset_index(drop=True)\n",
    "df_test = df_test.sample(frac=TEST_FRAC).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finance</td>\n",
       "      <td>The cheapest rentals in Valley Mills, Indianap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>music</td>\n",
       "      <td>Ticket Tracker: Willie, Aldean, Buble book sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movies</td>\n",
       "      <td>Bradley Cooper Makes Rare Public Appearance Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>travel</td>\n",
       "      <td>Disney World's Skyliner system up and running ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finance</td>\n",
       "      <td>Here's why the Nasdaq signals a strong finish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>finance</td>\n",
       "      <td>Here's how much new teachers make in every sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>finance</td>\n",
       "      <td>High prices drove home sales down in September...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sports</td>\n",
       "      <td>If the season ended today (it doesn't) Colts w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sports</td>\n",
       "      <td>Watch: Travis Etienne sets school record on go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sports</td>\n",
       "      <td>Michigan State AD: Mark Dantonio firing 'not e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               text\n",
       "0  finance  The cheapest rentals in Valley Mills, Indianap...\n",
       "1    music  Ticket Tracker: Willie, Aldean, Buble book sho...\n",
       "2   movies  Bradley Cooper Makes Rare Public Appearance Wi...\n",
       "3   travel  Disney World's Skyliner system up and running ...\n",
       "4  finance  Here's why the Nasdaq signals a strong finish ...\n",
       "5  finance  Here's how much new teachers make in every sta...\n",
       "6  finance  High prices drove home sales down in September...\n",
       "7   sports  If the season ended today (it doesn't) Colts w...\n",
       "8   sports  Watch: Travis Etienne sets school record on go...\n",
       "9   sports  Michigan State AD: Mark Dantonio firing 'not e..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5217, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.head(10))\n",
    "display(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>Thiem and Tsitsipas reach Paris Masters 3rd ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>Giants ask Astros for permission to interview ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>It's official: Mike Bohn is departing Cincinna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>foodanddrink</td>\n",
       "      <td>5 best things our food critic ate in the Twin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foodanddrink</td>\n",
       "      <td>Uptown Bar Sued By Songwriters Organization Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>finance</td>\n",
       "      <td>Lower mortgage rates are causing an epic housi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weather</td>\n",
       "      <td>Firefighters battle house fire at Cypress area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>health</td>\n",
       "      <td>Vitamin E acetate, used in THC vaping, is dang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sports</td>\n",
       "      <td>Mike Anthony: UConn's move to the Big East sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sports</td>\n",
       "      <td>Westlake at 50: The 50 most impactful sports f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                               text\n",
       "0        sports  Thiem and Tsitsipas reach Paris Masters 3rd ro...\n",
       "1        sports  Giants ask Astros for permission to interview ...\n",
       "2        sports  It's official: Mike Bohn is departing Cincinna...\n",
       "3  foodanddrink  5 best things our food critic ate in the Twin ...\n",
       "4  foodanddrink  Uptown Bar Sued By Songwriters Organization Fo...\n",
       "5       finance  Lower mortgage rates are causing an epic housi...\n",
       "6       weather  Firefighters battle house fire at Cypress area...\n",
       "7        health  Vitamin E acetate, used in THC vaping, is dang...\n",
       "8        sports  Mike Anthony: UConn's move to the Big East sho...\n",
       "9        sports  Westlake at 50: The 50 most impactful sports f..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4292, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_test.head(10))\n",
    "display(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples in the dataset are grouped into 8 news article category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sports          2637\n",
       "finance          620\n",
       "foodanddrink     495\n",
       "travel           462\n",
       "health           364\n",
       "weather          362\n",
       "music            160\n",
       "movies           117\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[LABEL_COL].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sports          2161\n",
       "finance          490\n",
       "foodanddrink     445\n",
       "health           355\n",
       "travel           353\n",
       "weather          270\n",
       "music            116\n",
       "movies           102\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[LABEL_COL].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a tokenizer \n",
    "\n",
    "Pipeline to remove stop words, urls, punct and lammatize words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### HELPERS #########################\n",
    "from spacy.lang.en import English\n",
    "def load_spacy_english_model(name: str = \"en_core_web_sm\") -> English:\n",
    "  \"\"\" Load a spacy English model\"\"\"\n",
    "  assert name.startswith(\"en\"), \"[ERROR] - Model returns a Spacy English model.\"\n",
    "  return spacy.load(name) \n",
    "\n",
    "def lemmatize(token: str) -> str:\n",
    "  \"\"\" Returns lemmatized token \"\"\"\n",
    "  return token.lemma_ \n",
    "\n",
    "def normalize(token: str, do_lemma: bool = True) -> str:\n",
    "  \"\"\" Normalize and Lemmatize token \"\"\"\n",
    "  return lemmatize(token).lower() if do_lemma else token.lower()\n",
    "\n",
    "def is_acceptable_token(token: str) -> bool:\n",
    "  \"\"\" Checks if a token is acceptable and not punction or url \"\"\"\n",
    "  return (not token.is_punct) & (not token.like_url) & token.is_alpha & (not token.is_stop)\n",
    "\n",
    "####################### END HELPERS #########################\n",
    "\n",
    "\n",
    "## Load Spacy nlp model \n",
    "nlp = load_spacy_english_model()\n",
    "\n",
    "def tokenize_doc(doc: str, \n",
    "                 model = nlp) -> List:\n",
    "  \"\"\" Tokenize a single document \"\"\"\n",
    "  parsed = model(doc)\n",
    "  acceptable_tokens = list(filter(is_acceptable_token, parsed))\n",
    "  return list(map(normalize, acceptable_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_tokenizer(doc, model=en):\n",
    "  return [x.lemma_.lower() for x in en(doc) if (x.is_alpha)&\n",
    "          (not x.like_url)&(not x.is_punct)&(not x.is_stop)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating tokenized representation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = [better_tokenizer(str(d)) for d in df_train['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False,min_df=2) \n",
    "tfidf = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False,min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocab: 7855\n"
     ]
    }
   ],
   "source": [
    "# **important** just fit on trained: prevents information from test in training \n",
    "cv_vecs = cv.fit_transform(news_data).toarray()\n",
    "tfidf_vecs = tfidf.fit_transform(news_data).toarray()\n",
    "\n",
    "\n",
    "# get out the vocab (same for tfidf)\n",
    "vocab = cv.vocabulary_\n",
    "print(\"Size of vocab:\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5217, 7855)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5217, 7855)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cv_vecs.shape)\n",
    "display(tfidf_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top words for each news category articles (Counts and TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top x words\n",
    "top_words = 10\n",
    "\n",
    "\n",
    "# Getting the correct index for rows in the train dataset. The original index are kept intact and not reset.\n",
    "\n",
    "categories_rows_indx = []\n",
    "\n",
    "for category in chosen_articles:\n",
    "    categories_rows_indx.append((category, df_train.index[df_train['category'] == category].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words using CountVectorizer\n",
      "sports category\n",
      "['night', 'coach', 'new', 'play', 'football', 'season', 'win', 'team', 'week', 'game']\n",
      "finance category\n",
      "['high', 'report', 'billion', 'million', 'city', 'home', 'new', 'company', 'say', 'year']\n",
      "foodanddrink category\n",
      "['taste', 'business', 'well', 'home', 'open', 'recipe', 'thanksgiving', 'food', 'restaurant', 'new']\n",
      "health category\n",
      "['lung', 'study', 'people', 'vaping', 'year', 'day', 'new', 'cancer', 'health', 'say']\n",
      "travel category\n",
      "['park', 'street', 'fire', 'time', 'flight', 'year', 'day', 'city', 'say', 'new']\n",
      "weather category\n",
      "['temperature', 'cold', 'morning', 'wind', 'storm', 'area', 'say', 'snow', 'weather', 'fire']\n",
      "movies category\n",
      "['time', 'year', 'hollywood', 'open', 'actor', 'trailer', 'star', 'movie', 'new', 'film']\n",
      "music category\n",
      "['say', 'band', 'time', 'singer', 'year', 'tour', 'awards', 'new', 'country', 'music']\n",
      "\n",
      "\n",
      "Top 10 words using TfidfVectorizer\n",
      "sports category\n",
      "['state', 'coach', 'nfl', 'play', 'football', 'season', 'team', 'win', 'week', 'game']\n",
      "finance category\n",
      "['stock', 'million', 'city', 'sale', 'new', 'home', 'billion', 'say', 'year', 'company']\n",
      "foodanddrink category\n",
      "['taste', 'business', 'recipe', 'chicken', 'cook', 'recipes', 'new', 'thanksgiving', 'food', 'restaurant']\n",
      "health category\n",
      "['weight', 'food', 'eat', 'sleep', 'lung', 'study', 'say', 'vaping', 'cancer', 'health']\n",
      "travel category\n",
      "['holiday', 'place', 'day', 'park', 'hotel', 'say', 'travel', 'flight', 'city', 'new']\n",
      "weather category\n",
      "['morning', 'wind', 'area', 'temperature', 'forecast', 'cold', 'storm', 'fire', 'snow', 'weather']\n",
      "movies category\n",
      "['terminator', 'oscar', 'actress', 'hollywood', 'star', 'new', 'actor', 'movie', 'film', 'trailer']\n",
      "music category\n",
      "['year', 'underwood', 'band', 'new', 'cma', 'tour', 'singer', 'country', 'awards', 'music']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for vectorizer, vecs  in [(cv, cv_vecs), (tfidf, tfidf_vecs)]:\n",
    "    print(f\"Top {top_words} words using {vectorizer.__class__.__name__}\")\n",
    "    for category, indx in categories_rows_indx:    \n",
    "        # sum counts\n",
    "        s_sum = vecs[indx].sum(axis=0)\n",
    "        # sort arguments\n",
    "        s_sorted = np.argsort(s_sum)\n",
    "        # print top words\n",
    "        print(f\"{category} category\")\n",
    "        print([vectorizer.get_feature_names()[x] for x in s_sorted[-top_words:]])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing with Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=8\n",
    "\n",
    "nmf = NMF(n_components=n_components)\n",
    "lda = LatentDirichletAllocation(n_components=n_components)\n",
    "\n",
    "# tfidf for nmf\n",
    "nmf_vecs = nmf.fit_transform(tfidf_vecs)\n",
    "\n",
    "# count for lda\n",
    "lda_vecs = lda.fit_transform(cv_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF Reconstruction err: 71.0989690395505\n",
      "LDA ELBO: 3318.2548779078006\n"
     ]
    }
   ],
   "source": [
    "print('NMF Reconstruction err:', nmf.reconstruction_err_)\n",
    "print('LDA ELBO:', lda.bound_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic model top 10 words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_components(model, word_features, top_display=8):\n",
    "    # utility for displaying respresentative words per component for topic models\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        top_words_idx = topic.argsort()[::-1][:top_display]\n",
    "        top_words = [word_features[i] for i in top_words_idx]\n",
    "        print(\" \".join(top_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying top 10 words in each topic using NMF(tfidf): \n",
      "Topic 0:\n",
      "game win season team play week sunday steelers\n",
      "Topic 1:\n",
      "new year city say restaurant well food time\n",
      "Topic 2:\n",
      "world astros series nationals game washington yankee houston\n",
      "Topic 3:\n",
      "patriots new england brady nfl tom belichick ravens\n",
      "Topic 4:\n",
      "weather snow forecast today cold temperature week winter\n",
      "Topic 5:\n",
      "football college week playoff school high ranking arizona\n",
      "Topic 6:\n",
      "fire county california wind say burn area home\n",
      "Topic 7:\n",
      "state michigan penn saturday ohio iowa young florida\n",
      "\n",
      "\n",
      "Displaying top 10 words in each topic using LDA(CountVectorizer): \n",
      "Topic 0:\n",
      "new say free sign old year thanksgiving time\n",
      "Topic 1:\n",
      "new patriots say week england nfl city brady\n",
      "Topic 2:\n",
      "say new city company day food state street\n",
      "Topic 3:\n",
      "fire weather say county snow area morning report\n",
      "Topic 4:\n",
      "nfl brown need bengals well know lions like\n",
      "Topic 5:\n",
      "tour year record world new houston win open\n",
      "Topic 6:\n",
      "year world series game astros time win nationals\n",
      "Topic 7:\n",
      "game week season win football team state play\n"
     ]
    }
   ],
   "source": [
    "print('Displaying top 10 words in each topic using NMF(tfidf): ')\n",
    "display_components(nmf, tfidf.get_feature_names())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Displaying top 10 words in each topic using LDA(CountVectorizer): ')\n",
    "display_components(lda, cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Fitting SVM models for TFIDF, CV, NMF, LDA and Glove vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data prep for SVM Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = df_train['text']\n",
    "y_train = df_train['category']\n",
    "X_test_text = df_test['text']\n",
    "y_test = df_test['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize models/vectorizers to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_components=8\n",
    "\n",
    "svc = LinearSVC()\n",
    "tfidf = TfidfVectorizer(tokenizer=better_tokenizer, min_df=2)\n",
    "cv = CountVectorizer(tokenizer=better_tokenizer, min_df=2)\n",
    "nmf = NMF(n_components=n_components)\n",
    "lda = LatentDirichletAllocation(n_components=n_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate different vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF featureset\n",
    "tfidf_train = tfidf.fit_transform(X_train_text)\n",
    "tfidf_test = tfidf.transform(X_test_text)\n",
    "\n",
    "# CV featureset\n",
    "cv_train = cv.fit_transform(X_train_text)\n",
    "cv_test = cv.transform(X_test_text)\n",
    "\n",
    "\n",
    "# NMF featureset\n",
    "nmf_train = nmf.fit_transform(tfidf_train)\n",
    "nmf_test = nmf.transform(tfidf_test)\n",
    "\n",
    "\n",
    "# Glove featureset\n",
    "glove_train = np.concatenate([nlp(doc).vector.reshape(1, -1) for doc in X_train_text])\n",
    "glove_test = np.concatenate([nlp(doc).vector.reshape(1, -1) for doc in X_test_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit SVC with all the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf Train acc :  0.9973164654015718\n",
      "tfidf Test acc :  0.8704566635601119\n",
      "\n",
      "\n",
      "cv Train acc :  0.9996166379145103\n",
      "cv Test acc :  0.8452935694315005\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/useradmin/miniconda3/envs/nlp_gpu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nmf Train acc :  0.603028560475369\n",
      "nmf Test acc :  0.5904007455731594\n",
      "\n",
      "\n",
      "glove Train acc :  0.9294613762698869\n",
      "glove Test acc :  0.8893289841565704\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit/predict on full dataset\n",
    "svc = LinearSVC(max_iter=10000)\n",
    "for pair in [(tfidf_train, tfidf_test, \"tfidf\"),\n",
    "             (cv_train, cv_test, \"cv\"),\n",
    "            (nmf_train, nmf_test, \"nmf\"),\n",
    "            (glove_train, glove_test, \"glove\"),\n",
    "            ]:\n",
    "    with Timer() as t:\n",
    "        svc.fit(pair[0], y_train)\n",
    "    train_time = t.interval / 3600\n",
    "    preds_test = svc.predict(pair[1])\n",
    "    preds_train = svc.predict(pair[0])\n",
    "    acc_train = accuracy_score(y_train, preds_train)\n",
    "    acc_test = accuracy_score(y_test, preds_test)\n",
    "    \n",
    "\n",
    "    class_report = classification_report(y_test, preds_test, output_dict=True)\n",
    "\n",
    "    MODEL_RESULTS[pair[2]] = {\n",
    "        \"Test Set Accuracy\": acc_test,\n",
    "        \"f1-score\": class_report[\"macro avg\"][\"f1-score\"],\n",
    "        \"time(hrs)\": train_time,\n",
    "    }\n",
    "    \n",
    "    print(f\"{pair[2]} Train acc : \",acc_train)\n",
    "    print(f\"{pair[2]} Test acc : \",acc_test)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation classical method results  \n",
    "\n",
    "At this point we can evaluate the accuracy and f1 scores obtained from running some of the classical NLP approaches for this type of scenario.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>time(hrs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>0.870457</td>\n",
       "      <td>0.796588</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>0.845294</td>\n",
       "      <td>0.761972</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nmf</th>\n",
       "      <td>0.590401</td>\n",
       "      <td>0.245774</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glove</th>\n",
       "      <td>0.889329</td>\n",
       "      <td>0.825142</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Test Set Accuracy  f1-score  time(hrs)\n",
       "tfidf           0.870457  0.796588   0.000038\n",
       "cv              0.845294  0.761972   0.000160\n",
       "nmf             0.590401  0.245774   0.000038\n",
       "glove           0.889329  0.825142   0.000516"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(MODEL_RESULTS).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Transformer Based Models  \n",
    "So far, it seems that `LinearSVC`, using `TfIdfVectorizer` performs the best. Now, we would like to compare the performance of this classical method, on various tokenization and vectorization strategies tried out earlier, against some State-Of-The-Art (SOTA) transformer based models that can be used in sequence classification problems.  \n",
    "\n",
    "For this, we will be using PyTorch and leveraging Hugging Face's implementation of these transformer based models.  \n",
    "\n",
    "### Selecting Pretrained Models\n",
    " Recently, we have experience a break-through in the world of NLP. There is abundant data and compute is a lot better to use. This has given birth to transformer models like starting from [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) (Devlin et. al). The challenge is that these transformer based models are training with a lot of parameters, making it too large to use in production. Operationalization costs for these large models  on-the-edge and/or under constrained computational training or inference budgets remains challenging.    \n",
    " \n",
    "Transfer Learning, a concept borrowed from Computer Vision, can now be applied on text; leading to smaller models, with similar architecture as their teacher models, that still have great performances. Transfer learning from very large pre-trained models has become more prevalent in Natural Language Processing (NLP). \n",
    "\n",
    " Several distilled pretrained models have been made available by [Hugging Face](https://github.com/huggingface/transformers). some of these models can be used for text/sequence classification. We will be using `distilBert, Roberta` and `XLNet` because of their size compared to other larger transformer models.  \n",
    " \n",
    "- [DistilBERT](https://huggingface.co/transformers/model_doc/distilbert.html) is a small, fast, cheap and light Transformer model trained by distilling Bert base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of Bert’s performances as measured on the GLUE language understanding benchmark. \n",
    "\n",
    "- [RoBERTa](https://huggingface.co/transformers/model_doc/roberta.html) was proposed in [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692) (Liu et.al). It is based on Google’s BERT model released in 2018. RoBERTa builds upon BERT, modifying key hyperparameters, removing the next-sentence pretraining objective and training with much larger mini-batches and learning rates.  \n",
    "\n",
    "- [XLNet](https://huggingface.co/transformers/model_doc/xlnet.html) was proposed in [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237) (Yang et. al). XLnet is an extension of the Transformer-XL model pre-trained using an autoregressive method to learn bidirectional contexts by maximizing the expected likelihood over all permutations of the input sequence factorization order.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Label Pre-processing and Encoding\n",
    "\n",
    "Let's start first by encoding the target label in the format the transformer models can use. For this we use the `LabelEncoder` from `skLearn` to tranform our target article labels. \n",
    "\n",
    "`LabelEncoder` encodes target labels with value between 0 and $n_classes-1$.\n",
    "\n",
    "> **NOTE:** `LabelEncoder` should be used to transform and encode just the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_train[LABEL_COL] = label_encoder.fit_transform(df_train[LABEL_COL])\n",
    "df_test[LABEL_COL] = label_encoder.transform(df_test[LABEL_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our target labels now look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       4\n",
       "2       3\n",
       "3       6\n",
       "4       0\n",
       "       ..\n",
       "5212    0\n",
       "5213    5\n",
       "5214    0\n",
       "5215    5\n",
       "5216    7\n",
       "Name: category, Length: 5217, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train[LABEL_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: 8\n",
      "Number of training examples: 5217\n",
      "Number of testing examples: 4292\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(np.unique(df_train[LABEL_COL]))\n",
    "print(\"Number of unique labels: {}\".format(num_labels))\n",
    "print(\"Number of training examples: {}\".format(df_train.shape[0]))\n",
    "print(\"Number of testing examples: {}\".format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now pre-processed, we have our train and test data splits, encoded our target labels. At this point, we are ready to start fine-tuning our data to the models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fine-tuning with News Article Data\n",
    "\n",
    "For this part, we choose an engineering design that abstracts the model fine-tuning code into reusable components that make it easy to build `sklearn` type of pipelines.  \n",
    "\n",
    "The decision to approach it this way was to make the code more readable, less bloated here on the notebook, and also production ready to be used in future projects.    \n",
    "\n",
    "Below we go into details describing the various classes we have defined and created.  \n",
    "\n",
    "### Wrapper Code Components - Overview and Description of the Code Classes\n",
    "\n",
    "Our wrappers make it easy to fine-tune different models in a unified way, hiding the preprocessing details that are needed before training. In this example, we're going to select the following models, listed below, and use the same piece of code to fine-tune them on our articles classification task. \n",
    "\n",
    "> **NOTE:** - Some models were pretrained on multilingual datasets and can be used with non-English datasets as well. Leveraging the Hugging Face `AutoModels`, it's easy to expand the scope of the models supported with our wrappers.  \n",
    "\n",
    "\n",
    "#### Code definitions  \n",
    "\n",
    "1. **DownloadMindDataset**: This is a utility class we wrote that handles downloading of the MIND dataset, if it does not exist, extracts the data, does some initial processing and returns a tuple of train and test dataframes. The class has the following static methods:  \n",
    "    - `download_from_url`: This method is responsible for downloading the MIND dataset from Azure Storage Blobs. It downloads a URL to a temporary file for further processing.   \n",
    "    \n",
    "    - `process_and_load_dfs`: Download MIND from a URL, process it and both training and test dataframes\n",
    "\n",
    "1. **ArticleTransformer**: This is a transfomer base class that abstracts all the functionality expected from a PyTorch transfomer models. It provides abstractions for setting up model parameters like saving and loading a trained checkpoint, creating a default optimizer and scheduler, setting up the model seed, parallelizing and distributing the tensors to all the GPUs available and more. Most importantly, it abstracts the following methods that will be have a concrete implementation in classes that inherit this:\n",
    "    - `fine_tune`\n",
    "    - `predict`\n",
    "\n",
    "1. **ArticleClassifier**:  This inherits from the **ArticleTransfomer** class. It implements the following methods based\n",
    "    - `fit`: This is a wrapper, and implementation of the `fine_tune` function from the parent class. This function helps to fine-tune a pre-trained sequence classification model.\n",
    "    - `predict`: This function helps to score a dataset using a fine-tuned model and a given dataloader.\n",
    "\n",
    "1. **ArticleClassificationDataProcessor**: This class for implements functionality for preprocessing the article classification data. The following are the major methods\n",
    "    - `create_dataset_from_dataframe`: This takes a Pandas dataframe, processes it and converts it into a PyTorch dataset.\n",
    "    - `create_dataset_from_dataframe`: This takes a PyTorch dataset, processes it and converts it into a PyTorch dataloader.  \n",
    "    - `get_inputs`: This creates an input dictionary, given a model name, which contains the input ids, segment ids, masks, and labels. The labels are only returned when `train_mode` is True.\n",
    "    - `text_transform`: This function is used for sequence classification. The function can be passed to a map-style PyTorch DataSet.\n",
    "\n",
    "1. **ArticleClassificationDataSet**: This inherits from PyTorch Dataset and creates a dataset for a single article/sequence classification tasks.\n",
    "\n",
    "\n",
    "> **NOTE:** All code wrappers and utilities can be found under the [src/common](./common) folder.  \n",
    "\n",
    "As a reminder, the following are the models we will be fine-tuning for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['distilbert-base-uncased', 'roberta-base', 'xlnet-base-cased']\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each pretrained model, we preprocess the data, create PyTorch datasets from dataframes, convert those datasets into dataloaders. Then we fine-tune the classifier, using the dataloaders, score on the test set, and store the evaluation results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 135/135 [00:28<00:00,  4.67it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8519503d8ee4b1492355e0097d524a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=481, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f424b5777f4110bfa329c626914ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=898823, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a84e69207c405bbeb6c101b627aea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=456318, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53cc66606aa4e418e2b4cbaed703c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=501200538, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring: 100%|██████████| 135/135 [00:50<00:00,  2.69it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0de96f273042d7b2660ffa68d67b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=760, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3103c31327a49478cf28566f888e8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=798011, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fac44eba8014077846d3add689019c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=467042463, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/useradmin/miniconda3/envs/nlp_gpu/lib/python3.6/site-packages/transformers/modeling_xlnet.py:271: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629416375/work/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
      "  attn_score = (ac + bd + ef) * self.scale\n",
      "Scoring: 100%|██████████| 135/135 [01:15<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "for name in tqdm(MODEL_NAMES, disable=True):\n",
    "\n",
    "    # preprocess steps\n",
    "    # 1. Dataframe --> PyTorch Dataset\n",
    "    # 2. Dataset --> PyTorch Dataloader\n",
    "    processor = ArticleClassificationDataProcessor(\n",
    "        model_name=str(name),\n",
    "        to_lower=name.endswith(\"uncased\"),\n",
    "        batch_size=BATCH_SIZE, \n",
    "        num_gpus=NUM_GPUS,\n",
    "        cache_dir=CACHE_DIR\n",
    "    )\n",
    "    \n",
    "    # Defining training artifacts from the processor\n",
    "    train_dataset = processor.create_dataset_from_dataframe(df_train, TEXT_COL, LABEL_COL, max_len=MAX_LEN)\n",
    "    train_dataloader = processor.create_dataloader_from_dataset(train_dataset, shuffle=True)\n",
    "    \n",
    "    # Defining test artifacts from the processor\n",
    "    test_dataset = processor.create_dataset_from_dataframe(df_test, TEXT_COL, LABEL_COL, max_len=MAX_LEN)\n",
    "    test_dataloader = processor.create_dataloader_from_dataset(test_dataset, shuffle=False)\n",
    "\n",
    "    # fine-tune the classifier using our article dataloader\n",
    "    classifier = ArticleClassifier(model_name=name, num_labels=num_labels, cache_dir=CACHE_DIR)\n",
    "    with Timer() as t:\n",
    "        classifier.fit(\n",
    "            train_dataloader, num_epochs=NUM_EPOCHS, num_gpus=NUM_GPUS, verbose=False,\n",
    "        )\n",
    "    # compute amount of time to run epoch\n",
    "    train_time = t.interval / 3600\n",
    "\n",
    "    # predict on the test set\n",
    "    preds = classifier.predict(test_dataloader, num_gpus=NUM_GPUS, verbose=True)\n",
    "\n",
    "    # evaluate the model accuracy \n",
    "    accuracy = accuracy_score(df_test[LABEL_COL], preds)\n",
    "    class_report = classification_report(\n",
    "        df_test[LABEL_COL], preds, target_names=label_encoder.classes_, output_dict=True\n",
    "    )\n",
    "\n",
    "    # save results\n",
    "    MODEL_RESULTS[name] = {\n",
    "        \"Test Set Accuracy\": accuracy,\n",
    "        \"f1-score\": class_report[\"macro avg\"][\"f1-score\"],\n",
    "        \"time(hrs)\": train_time,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "Finally, we report the accuracy and F1-score metrics for each model, as well as the fine-tuning time in hours.  \n",
    "\n",
    "> For the sake of time, matching up to the classical method and computation cost, we've decided to fine-tune the model on just a single epoch. We already observe very good accuracy, however, please modify `NUM_EPOCHS` to increase the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>time(hrs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>0.870457</td>\n",
       "      <td>0.796588</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>0.845294</td>\n",
       "      <td>0.761972</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nmf</th>\n",
       "      <td>0.590401</td>\n",
       "      <td>0.245774</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glove</th>\n",
       "      <td>0.889329</td>\n",
       "      <td>0.825142</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert-base-uncased</th>\n",
       "      <td>0.905638</td>\n",
       "      <td>0.844936</td>\n",
       "      <td>0.023814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-base</th>\n",
       "      <td>0.911696</td>\n",
       "      <td>0.858925</td>\n",
       "      <td>0.046747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlnet-base-cased</th>\n",
       "      <td>0.912628</td>\n",
       "      <td>0.855437</td>\n",
       "      <td>0.066819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Test Set Accuracy  f1-score  time(hrs)\n",
       "tfidf                             0.870457  0.796588   0.000038\n",
       "cv                                0.845294  0.761972   0.000160\n",
       "nmf                               0.590401  0.245774   0.000038\n",
       "glove                             0.889329  0.825142   0.000516\n",
       "distilbert-base-uncased           0.905638  0.844936   0.023814\n",
       "roberta-base                      0.911696  0.858925   0.046747\n",
       "xlnet-base-cased                  0.912628  0.855437   0.066819"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(MODEL_RESULTS).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion  \n",
    "\n",
    "In conclusion, this notebook walks us through various NLP techniques; from classically to State-Of-The-Art transformer models.  \n",
    "\n",
    "\n",
    "### Data and Results\n",
    "We used the Microsoft MIND at Work News Recommendation dataset to fine-tune news article classification. We see that just for a single epoch, the `xlnet-base-cased` performs the best on the small dataset from MIND at Work. This confirms our hypothesis, that transformer models are indeed SOTA and should outperform classical methods for text classification.  \n",
    "\n",
    "\n",
    "### Code \n",
    "We created reusable wrappers of code that makes it easy to abstract the data processing, tokenization, vectorization and fine-tuning of models. Our wrappers make it easy to expand to other models supported by the Hugging Face PyTorch library for single sentence sequence classification.  \n",
    "\n",
    "### Future Work  \n",
    "\n",
    "1. Build a news recommendation engine that uses our fine-tuned models  \n",
    "\n",
    "1. Plug in our wrappers and make it easy to switch between various fine-tuned models for text classification  \n",
    "\n",
    "1. Create a UI component and application  \n",
    "\n",
    "\n",
    "### References  \n",
    "\n",
    "1. [Microsoft MIND at work:](https://blogs.msn.com/mind-at-work-news-recommendation-challenge-for-researchers/)  News recommendation competition open to researchers and publishers\n",
    "\n",
    "1. [Microsoft NLP Recipes](https://github.com/microsoft/nlp-recipes)\n",
    "\n",
    "1. [Hugging Face Transformers](https://github.com/huggingface/transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_gpu)",
   "language": "python",
   "name": "nlp_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
